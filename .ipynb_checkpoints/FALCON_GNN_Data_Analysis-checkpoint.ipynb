{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6ba4ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from model.GNN_Model import GNN_Model\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from ops.os_operation import mkdir\n",
    "import shutil\n",
    "import  numpy as np\n",
    "from data_processing.Prepare_Input import Prepare_Input\n",
    "from data_processing.Single_Dataset import Single_Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from data_processing.collate_fn import collate_fn_Jake\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dd1225",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_multi_input(input_path, params):\n",
    "    save_path = os.path.join(os.getcwd(), \"Predict_Result\")\n",
    "    mkdir(save_path)\n",
    "    save_path = os.path.join(save_path, \"Multi_Target\")\n",
    "    mkdir(save_path)\n",
    "    save_path = os.path.join(save_path, \"Fold_\" + str(params['fold']) + \"_Result\")\n",
    "    mkdir(save_path)\n",
    "    input_path=os.path.abspath(input_path)\n",
    "    folder_name=os.path.split(input_path)[1]\n",
    "    save_path = os.path.join(save_path, folder_name)\n",
    "    mkdir(save_path)\n",
    "\n",
    "    fold_choice = params['fold']\n",
    "    # loading the model\n",
    "    if fold_choice != -1:\n",
    "        model_path = os.path.join(os.getcwd(), \"best_model\")\n",
    "        model_path = os.path.join(model_path, \"fold\" + str(fold_choice))\n",
    "        model_path = os.path.join(model_path, \"checkpoint.pth.tar\")\n",
    "        model, device = init_model(model_path, params)\n",
    "    else:\n",
    "        root_model_path = os.path.join(os.getcwd(), \"best_model\")\n",
    "        model_list = []\n",
    "        for k in range(1, 4):\n",
    "            model_path = os.path.join(root_model_path, \"fold\" + str(k))\n",
    "            model_path = os.path.join(model_path, \"checkpoint.pth.tar\")\n",
    "            model, device = init_model(model_path, params)\n",
    "            model_list.append(model)\n",
    "        model = model_list\n",
    "\n",
    "    listfiles=[x for x in os.listdir(input_path) if \".pdb\" in x]\n",
    "    listfiles.sort()\n",
    "    Study_Name=[]\n",
    "    Input_File_List=[]\n",
    "    for item in listfiles:\n",
    "        input_pdb_path=os.path.join(input_path,item)\n",
    "        cur_root_path = os.path.join(save_path, item[:-4])\n",
    "        Study_Name.append(item[:-4])\n",
    "        mkdir(cur_root_path)\n",
    "        structure_path=os.path.join(cur_root_path,\"Input.pdb\")\n",
    "        shutil.copy(input_pdb_path, structure_path)\n",
    "        input_file = Prepare_Input(structure_path)\n",
    "        Input_File_List.append(input_file)\n",
    "    list_npz = Input_File_List\n",
    "    dataset = Single_Dataset(list_npz)\n",
    "    dataloader = DataLoader(dataset, params['batch_size'], shuffle=False,\n",
    "                            num_workers=params['num_workers'],\n",
    "                            drop_last=False, collate_fn=collate_fn)\n",
    "\n",
    "    # prediction\n",
    "    if fold_choice != -1:\n",
    "        Final_Pred = Get_Predictions(dataloader, device, model)\n",
    "    else:\n",
    "        Final_Pred = []\n",
    "        for cur_model in model:\n",
    "            tmp_pred = Get_Predictions(dataloader, device, cur_model)\n",
    "            Final_Pred.append(tmp_pred)\n",
    "        Final_Pred = np.mean(Final_Pred, axis=0)\n",
    "    pred_path = os.path.join(save_path, 'Predict.txt')\n",
    "    with open(pred_path, 'w') as file:\n",
    "        file.write(\"Input\\tScore\\n\")\n",
    "        for k in range(len(Input_File_List)):\n",
    "            file.write(Study_Name[k] + \"\\t%.4f\\n\" % Final_Pred[k])\n",
    "    pred_sort_path=os.path.join(save_path,\"Predict_sort.txt\")\n",
    "    os.system(\"sort -n -k 2 -r \"+pred_path+\" >\"+pred_sort_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76e576de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def initialize_model(model, device, load_save_file=False):\n",
    "    if load_save_file:\n",
    "        model.load_state_dict(torch.load(load_save_file))\n",
    "    else:\n",
    "        for param in model.parameters():\n",
    "            if param.dim() == 1:\n",
    "                continue\n",
    "                nn.init.constant(param, 0)\n",
    "            else:\n",
    "                #nn.init.normal(param, 0.0, 0.15)\n",
    "                nn.init.xavier_normal_(param)\n",
    "\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "        model = nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "def init_model(model_path,params):\n",
    "    model = GNN_Model(params)\n",
    "    print('    Total params: %.10fM' % (count_parameters(model) / 1000000.0))\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = initialize_model(model, device)\n",
    "    state_dict = torch.load(model_path, map_location = device)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "    return model,device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d365537",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Predictions(dataloader,device,model):\n",
    "    Final_pred = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, sample in enumerate(dataloader):\n",
    "            H, A1, A2, V, Atom_count = sample\n",
    "            batch_size = H.size(0)\n",
    "            H, A1, A2, V = H.to(device), A1.to(device), A2.to(device), V.to(device)\n",
    "            pred= model.test_model((H, A1, A2, V, Atom_count), device)\n",
    "            pred1 = pred.detach().cpu().numpy()\n",
    "            Final_pred += list(pred1)\n",
    "    return Final_pred\n",
    "\n",
    "def test_falcon_gnn(input_path, params):\n",
    "    '''\n",
    "    Trains the GNN according to Jake's parameters.\n",
    "    FALCON_GNN stands for Fucking Awesome Linking\n",
    "    Cohort Of Nottingham, which I just made up\n",
    "    '''\n",
    "    ## Get all the NPZ files from the input_path\n",
    "\n",
    "    list_npz = [f for f in listdir(input_path) if isfile(join(input_path, f)) and f.endswith(\".npz\")]\n",
    "    fold1_label = ['1a2k', '1e96', '1he1', '1he8', '1wq1', '1f6m', '1ma9', '2btf', '1g20', '1ku6', '1t6g', '1ugh', '1yvb', '2ckh', '3pro']\n",
    "    fold2_label = ['1akj', '1p7q', '2bnq', '1dfj', '1nbf', '1r4m', '1xd3', '2bkr', '1gpw', '1hxy', '1u7f', '1uex', '1zy8', '2goo', '1ewy']\n",
    "    fold3_label = ['1avw', '1bth', '1bui', '1cho', '1ezu', '1ook', '1oph', '1ppf', '1tx6', '1xx9', '2fi4', '2kai', '1r0r', '2sni', '3sic']\n",
    "    fold4_label = ['1bvn', '1tmq', '1f51', '1fm9', '1a2y', '1g6v', '1gpq', '1jps', '1wej', '1l9b', '1s6v', '1w1i', '2a5t', '3fap']\n",
    "\n",
    "    train_data_list = []\n",
    "    test_data_list = []\n",
    "    for file in list_npz:\n",
    "        if file[:4] in fold1_label or file[:4] in fold3_label or file[:4] in fold4_label:\n",
    "            train_data_list.append(file)\n",
    "        elif file[:4] in fold2_label:\n",
    "            test_data_list.append(file)\n",
    "    \n",
    "    ## Just to test it out\n",
    "    test_data_list = test_data_list[:10]\n",
    "    \n",
    "    train_data = Single_Dataset(train_data_list)\n",
    "    test_data = Single_Dataset(test_data_list)\n",
    "    #train_data, test_data = random_split(dataset, [0.75, 0.25])\n",
    "\n",
    "    BATCH_SIZE = 10\n",
    "\n",
    "    train_loader = DataLoader(train_data, BATCH_SIZE, shuffle=False,\n",
    "                            num_workers=params['num_workers'],\n",
    "                            drop_last=False, collate_fn=collate_fn_Jake)\n",
    "\n",
    "    test_loader = DataLoader(test_data, BATCH_SIZE, shuffle=False,\n",
    "                            num_workers=params['num_workers'],\n",
    "                            drop_last=False, collate_fn=collate_fn_Jake)\n",
    "\n",
    "    ## Initialize Model from saved state\n",
    "    \n",
    "    \n",
    "    model_path = \"/mnt/c/Users/jaket/Documents/GNN_DOVE_DATA/full_train_DG1_random_batch_jake_params_3.pt\"\n",
    "    model, device = init_model(model_path, params)\n",
    "    \n",
    "    ## Get predictions for the model\n",
    "\n",
    "    Final_Pred = Get_Predictions(test_loader, device, model)\n",
    "     \n",
    "    return test_data_list, Final_Pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f29aa02",
   "metadata": {},
   "source": [
    "## Actually testing the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "256a9799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Total params: 9.5805500000M\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 23\u001b[0m\n\u001b[1;32m      3\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexample\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreceptor_units\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     19\u001b[0m }\n\u001b[1;32m     22\u001b[0m input_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/mnt/c/Users/jaket/Documents/GNN_DOVE_DATA/dockground_1_processed_npz\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 23\u001b[0m \u001b[43mtest_falcon_gnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 60\u001b[0m, in \u001b[0;36mtest_falcon_gnn\u001b[0;34m(input_path, params)\u001b[0m\n\u001b[1;32m     56\u001b[0m model, device \u001b[38;5;241m=\u001b[39m init_model(model_path, params)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m## Get predictions for the model\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m Final_Pred \u001b[38;5;241m=\u001b[39m Get_Predictions(\u001b[43mdataloader\u001b[49m, device, model)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m test_data_list, Final_Pred\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "## Getting params in the same format as the actual program\n",
    "\n",
    "params = {\n",
    "    'F' : 'example',\n",
    "    'mode' : '3',\n",
    "    'gpu' : '0',\n",
    "    'batch_size' : 32,\n",
    "    'num_workers' : 7,\n",
    "    'n_graph_layer' : 3,\n",
    "    'd_graph_layer' : 1024,\n",
    "    'n_FC_layer' : 4,\n",
    "    'd_FC_layer' : 128,\n",
    "    'initial_mu' : 0.0,\n",
    "    'initial_dev' : 1.0,\n",
    "    'dropout_rate' : 0.3,\n",
    "    'seed' : 888,\n",
    "    'fold' : -1,\n",
    "    'receptor_units' : 1,\n",
    "}\n",
    "\n",
    "\n",
    "input_path = \"/mnt/c/Users/jaket/Documents/GNN_DOVE_DATA/dockground_1_processed_npz\"\n",
    "test_falcon_gnn(input_path, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3020761b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/mnt/c/Users/jaket/Documents/GitHub/GNN_DOVE/predict/predict_single_input.py\u001b[0m(53)\u001b[0;36minit_model\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     51 \u001b[0;31m    \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     52 \u001b[0;31m    \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 53 \u001b[0;31m    \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     54 \u001b[0;31m    \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     55 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> p state_dict\n",
      "OrderedDict([('mu', tensor([-0.0048], device='cuda:0')), ('dev', tensor([0.9940], device='cuda:0')), ('gconv1.0.A', tensor([[-7.1046e-02, -2.7105e-02,  5.1460e-04,  ..., -8.8450e-03,\n",
      "          4.6385e-02, -2.4563e-02],\n",
      "        [ 6.2323e-03,  2.4495e-02,  4.5495e-02,  ...,  9.7513e-03,\n",
      "          3.8024e-02, -4.2786e-02],\n",
      "        [-3.4971e-02,  7.7131e-03, -4.2729e-02,  ..., -4.6145e-03,\n",
      "         -1.1789e-02, -4.3933e-02],\n",
      "        ...,\n",
      "        [ 5.4928e-02,  4.0961e-03, -1.5767e-02,  ..., -4.1865e-02,\n",
      "          3.3878e-02, -7.7697e-03],\n",
      "        [-4.5457e-05, -2.2136e-02,  1.4759e-02,  ..., -1.9452e-02,\n",
      "          4.0685e-03,  2.7183e-03],\n",
      "        [ 3.6828e-03, -2.2368e-02, -1.3016e-02,  ...,  1.9972e-02,\n",
      "         -6.8171e-02, -8.9041e-03]], device='cuda:0')), ('gconv1.0.W.weight', tensor([[-0.0007,  0.0065,  0.0023,  ..., -0.0099,  0.0242, -0.0194],\n",
      "        [ 0.0225, -0.0707, -0.0420,  ...,  0.0140, -0.0358, -0.0320],\n",
      "        [ 0.0338, -0.0368, -0.0278,  ..., -0.0029, -0.0560,  0.0154],\n",
      "        ...,\n",
      "        [ 0.0080, -0.0063, -0.0253,  ...,  0.0087,  0.0050, -0.0218],\n",
      "        [ 0.0293, -0.0338, -0.0038,  ..., -0.0097, -0.0399, -0.0491],\n",
      "        [ 0.0277,  0.0349,  0.0055,  ..., -0.0265, -0.0017,  0.0496]],\n",
      "       device='cuda:0')), ('gconv1.0.W.bias', tensor([-0.0255,  0.0051,  0.0267,  ..., -0.0057, -0.0296, -0.0179],\n",
      "       device='cuda:0')), ('gconv1.0.gate.weight', tensor([[ 0.0407, -0.0147,  0.0088,  ...,  0.0303, -0.0200, -0.0216]],\n",
      "       device='cuda:0')), ('gconv1.0.gate.bias', tensor([0.0103], device='cuda:0')), ('gconv1.1.A', tensor([[-0.0058, -0.0083, -0.0053,  ..., -0.0429, -0.0012,  0.0170],\n",
      "        [-0.0066,  0.0260, -0.0471,  ..., -0.0142, -0.0290, -0.0238],\n",
      "        [ 0.0702,  0.0053, -0.0426,  ..., -0.0096, -0.0362, -0.0525],\n",
      "        ...,\n",
      "        [ 0.0234,  0.0419, -0.0177,  ...,  0.0054,  0.0013,  0.0071],\n",
      "        [-0.0115, -0.0262,  0.0346,  ..., -0.0053, -0.0725, -0.0181],\n",
      "        [ 0.0041,  0.0911,  0.0539,  ...,  0.0255, -0.0171, -0.0283]],\n",
      "       device='cuda:0')), ('gconv1.1.W.weight', tensor([[ 0.0349,  0.0325, -0.0141,  ...,  0.0318, -0.0118, -0.0211],\n",
      "        [-0.0217, -0.0124,  0.0241,  ...,  0.0017, -0.0037,  0.0180],\n",
      "        [ 0.0021,  0.0220,  0.0160,  ...,  0.0359,  0.0344,  0.0089],\n",
      "        ...,\n",
      "        [ 0.0262,  0.0133,  0.0412,  ..., -0.0693, -0.0130, -0.0584],\n",
      "        [ 0.0354, -0.0237, -0.0518,  ...,  0.0512, -0.0315, -0.0458],\n",
      "        [ 0.0239, -0.0127, -0.0031,  ..., -0.0193, -0.0031, -0.0005]],\n",
      "       device='cuda:0')), ('gconv1.1.W.bias', tensor([ 0.0089,  0.0075,  0.0186,  ..., -0.0072,  0.0288,  0.0085],\n",
      "       device='cuda:0')), ('gconv1.1.gate.weight', tensor([[-0.0342, -0.0623,  0.0188,  ...,  0.0264, -0.0335,  0.0045]],\n",
      "       device='cuda:0')), ('gconv1.1.gate.bias', tensor([0.0085], device='cuda:0')), ('gconv1.2.A', tensor([[-0.0036,  0.0271,  0.0142,  ...,  0.0518,  0.0079,  0.0115],\n",
      "        [-0.0071,  0.0274,  0.0367,  ..., -0.0023,  0.0377,  0.0342],\n",
      "        [-0.0148, -0.0300, -0.0030,  ..., -0.0235,  0.0303,  0.0497],\n",
      "        ...,\n",
      "        [-0.0273, -0.0178, -0.0010,  ...,  0.0317,  0.0122,  0.0533],\n",
      "        [ 0.0108,  0.0064,  0.0046,  ...,  0.0563, -0.0064, -0.0144],\n",
      "        [ 0.0083, -0.0688,  0.0219,  ...,  0.0450, -0.0060, -0.0538]],\n",
      "       device='cuda:0')), ('gconv1.2.W.weight', tensor([[ 0.0484, -0.0090,  0.0062,  ..., -0.0310,  0.0348, -0.0098],\n",
      "        [ 0.0137,  0.0257, -0.0299,  ..., -0.0212, -0.0648,  0.0219],\n",
      "        [-0.0394, -0.0484, -0.0034,  ..., -0.0703, -0.0168, -0.0494],\n",
      "        ...,\n",
      "        [ 0.0221, -0.0146, -0.0035,  ..., -0.0705,  0.0129, -0.0414],\n",
      "        [ 0.0286, -0.0779, -0.0273,  ..., -0.0059,  0.0477,  0.0062],\n",
      "        [ 0.0072, -0.0307,  0.0532,  ...,  0.0100, -0.0133, -0.0049]],\n",
      "       device='cuda:0')), ('gconv1.2.W.bias', tensor([-0.0286, -0.0019, -0.0070,  ..., -0.0233, -0.0144,  0.0315],\n",
      "       device='cuda:0')), ('gconv1.2.gate.weight', tensor([[ 0.0140, -0.0304, -0.0007,  ..., -0.0051,  0.0928,  0.0078]],\n",
      "       device='cuda:0')), ('gconv1.2.gate.bias', tensor([0.0195], device='cuda:0')), ('FC.0.weight', tensor([[-0.0010,  0.0186, -0.0295,  ..., -0.0263,  0.0406,  0.0179],\n",
      "        [ 0.0034,  0.0136, -0.0066,  ..., -0.0046, -0.0203, -0.0384],\n",
      "        [-0.0574,  0.0406,  0.0218,  ..., -0.0176,  0.0236, -0.0027],\n",
      "        ...,\n",
      "        [ 0.0441,  0.0261,  0.0368,  ..., -0.0435, -0.0270,  0.0263],\n",
      "        [ 0.0155, -0.0194,  0.0058,  ...,  0.0320,  0.0443, -0.0334],\n",
      "        [-0.0206, -0.0342, -0.0090,  ...,  0.0099,  0.0199,  0.0483]],\n",
      "       device='cuda:0')), ('FC.0.bias', tensor([ 0.0012,  0.0100, -0.0136,  ...,  0.0266,  0.0023, -0.0183],\n",
      "       device='cuda:0')), ('FC.1.weight', tensor([[ 0.0349,  0.0092, -0.0187,  ...,  0.0411,  0.0104,  0.0135],\n",
      "        [-0.0017, -0.0195, -0.0178,  ..., -0.0481,  0.0196,  0.0097],\n",
      "        [-0.0142,  0.0125, -0.0225,  ..., -0.0139,  0.0434,  0.0456],\n",
      "        ...,\n",
      "        [ 0.0116, -0.0134, -0.0361,  ..., -0.0399, -0.0285, -0.0429],\n",
      "        [-0.0078,  0.0322, -0.0156,  ..., -0.0162,  0.0092,  0.0241],\n",
      "        [-0.0139, -0.0194,  0.0012,  ...,  0.0336, -0.0022,  0.0351]],\n",
      "       device='cuda:0')), ('FC.1.bias', tensor([ 1.1858e-02,  1.9181e-02,  3.6771e-03,  1.5906e-03,  8.5141e-03,\n",
      "         9.5879e-03, -6.6711e-04,  4.0011e-03,  3.9693e-03,  2.6744e-02,\n",
      "        -2.3939e-03, -7.3798e-03, -1.9348e-02, -3.8161e-03,  3.2451e-04,\n",
      "        -3.5865e-03,  2.3766e-02, -1.4733e-03, -4.2213e-03, -1.6997e-03,\n",
      "        -2.6048e-02, -2.1538e-03,  2.8675e-02, -2.4535e-04,  5.9783e-03,\n",
      "        -8.6016e-04, -1.4744e-02, -8.2646e-03,  1.5187e-02,  7.7196e-03,\n",
      "        -6.2585e-03, -2.3688e-02, -1.9508e-02, -5.5715e-03, -1.9992e-02,\n",
      "        -1.8381e-02, -2.3704e-03,  1.0917e-02, -1.5055e-02,  7.6525e-03,\n",
      "         1.1747e-02, -4.7926e-03,  3.9290e-03, -4.7496e-03,  6.5455e-03,\n",
      "         2.1119e-02,  4.0537e-03, -3.7966e-03, -2.4539e-02, -2.9648e-03,\n",
      "        -1.8512e-02, -1.4871e-02,  1.3519e-02,  3.8953e-03, -1.4764e-02,\n",
      "        -2.3403e-03,  2.1161e-02,  8.8172e-04, -6.8278e-03,  1.3659e-03,\n",
      "        -1.7180e-03,  8.0133e-03, -9.2654e-03, -1.1261e-02, -1.8518e-02,\n",
      "        -9.4801e-03,  9.6070e-03, -4.2242e-03, -1.5345e-02, -1.9333e-02,\n",
      "        -2.9221e-04, -2.8323e-02, -2.3508e-02, -1.5896e-03,  1.6032e-02,\n",
      "        -1.8577e-02, -1.1190e-02,  1.7951e-02,  2.2067e-02,  1.5498e-03,\n",
      "        -2.8527e-04,  2.7468e-03,  9.4272e-03, -2.0531e-02, -1.3190e-02,\n",
      "         6.1583e-03, -1.9955e-02, -5.4865e-03,  1.4085e-02,  1.3624e-02,\n",
      "         2.0965e-02,  8.3576e-03,  1.4710e-02, -1.8079e-02, -2.4303e-02,\n",
      "         1.4900e-02,  3.5475e-03,  1.3364e-02, -1.8479e-02, -9.3168e-03,\n",
      "         2.3453e-02, -7.6709e-03,  2.5696e-03,  5.5299e-03, -4.1982e-03,\n",
      "        -1.0520e-02,  1.5971e-03,  9.9280e-03,  1.0039e-02, -2.4881e-02,\n",
      "         3.9407e-03, -6.8447e-04, -8.9673e-03, -1.0830e-02, -1.7853e-02,\n",
      "         1.8349e-02,  9.6789e-03, -1.8646e-02, -3.1633e-03, -1.0095e-02,\n",
      "        -1.7081e-02, -1.5890e-02, -1.8882e-02,  2.1976e-02,  5.4860e-03,\n",
      "         1.2906e-02,  7.2487e-03, -7.8187e-03,  1.1286e-02, -1.4208e-02,\n",
      "         2.5885e-02, -7.8653e-03,  1.7116e-02, -6.6579e-03,  1.8126e-02,\n",
      "        -2.2092e-02, -1.0413e-02,  2.6660e-02, -2.4409e-03, -1.9819e-03,\n",
      "         1.3877e-02, -2.4687e-03,  5.7595e-03, -2.9823e-03, -3.6317e-04,\n",
      "         2.1464e-03,  1.4200e-02, -1.0004e-02,  8.0562e-03,  6.4232e-03,\n",
      "        -2.6699e-03,  2.2301e-02, -5.5774e-03, -9.9200e-03, -1.7620e-03,\n",
      "        -1.6366e-03, -6.1448e-03,  2.1531e-02,  2.1086e-02,  1.1132e-02,\n",
      "         1.6737e-02, -2.4477e-02,  7.3333e-03,  2.4490e-02,  1.6262e-02,\n",
      "        -1.8601e-02, -1.8063e-02, -2.8821e-02,  1.3768e-02,  2.0873e-02,\n",
      "        -1.7999e-02,  2.2094e-02,  1.9956e-02, -4.5921e-03,  7.6626e-04,\n",
      "         1.8072e-02, -1.6819e-02,  7.4770e-03,  1.4487e-03, -1.5840e-02,\n",
      "         2.8087e-03, -1.9131e-02,  6.2008e-03,  2.5238e-04,  9.2564e-03,\n",
      "         2.1943e-02,  1.5593e-03, -2.9691e-03, -2.0360e-02, -5.6746e-03,\n",
      "        -6.9320e-03, -4.0865e-04,  1.6230e-02, -3.1490e-03, -6.0072e-05,\n",
      "         1.9609e-02, -4.0687e-03, -1.6141e-02,  2.3048e-02,  2.4999e-03,\n",
      "        -2.2433e-02, -1.3758e-02,  6.0770e-03, -1.9325e-02,  2.4052e-02,\n",
      "         3.2225e-03, -5.9602e-03,  1.0204e-02, -3.1684e-03, -1.6743e-02,\n",
      "        -1.0700e-02,  1.3548e-02, -1.6222e-02,  9.5720e-04, -1.6049e-02,\n",
      "        -2.0571e-03, -3.0017e-03, -3.5675e-03,  9.0834e-03, -2.5910e-02,\n",
      "        -1.6793e-02, -5.5514e-03,  9.2581e-03, -6.8279e-03,  4.3742e-04,\n",
      "        -2.8586e-03,  1.9163e-02, -8.5860e-03, -1.0629e-02, -5.7014e-03,\n",
      "         1.8131e-02,  1.3336e-02, -1.3015e-02,  2.0027e-02, -8.2628e-03,\n",
      "        -1.0419e-02,  1.5565e-02,  9.7812e-03, -1.7849e-02,  1.1897e-02,\n",
      "         2.3475e-02,  2.5710e-02, -1.0711e-02, -1.1564e-02, -1.4408e-02,\n",
      "        -6.2926e-03, -1.9334e-04,  9.6269e-03, -6.9535e-03,  1.8358e-03,\n",
      "        -1.1228e-02,  8.1934e-03, -2.5912e-02, -1.6068e-02, -2.3240e-03,\n",
      "         7.5400e-04,  2.0065e-02, -2.8910e-04,  2.1691e-02, -1.3354e-02,\n",
      "         1.1794e-02,  2.3657e-02,  1.6607e-03,  1.3075e-02,  4.3213e-03,\n",
      "         2.7264e-02,  4.4433e-03, -2.0827e-02, -2.1443e-02, -1.9752e-02,\n",
      "         5.5949e-03,  1.3519e-02, -6.8578e-03,  2.2069e-02,  9.6263e-03,\n",
      "        -1.6757e-02,  5.6317e-03,  1.3070e-02,  5.0619e-03, -8.9902e-03,\n",
      "        -1.4518e-02, -1.7035e-02,  1.1012e-02, -7.1400e-03, -2.5766e-02,\n",
      "        -2.6594e-02,  7.9695e-03,  7.8468e-04, -1.8700e-02,  6.5957e-03,\n",
      "         1.0296e-02,  6.6230e-03, -4.3523e-03,  2.2053e-02,  3.0056e-03,\n",
      "         1.7984e-02, -4.0555e-03,  8.6942e-03,  2.0056e-02, -2.4581e-03,\n",
      "        -1.0588e-02,  2.5848e-02, -8.8011e-03,  1.8347e-03, -2.3934e-02,\n",
      "         7.0149e-03,  4.2546e-03,  9.8241e-03, -2.2737e-02,  1.8209e-02,\n",
      "         2.4163e-02, -1.0090e-02, -1.4597e-02, -1.8348e-02,  1.3473e-02,\n",
      "         1.7029e-03, -2.7130e-02, -6.0261e-03, -2.1814e-02,  1.1192e-02,\n",
      "         1.5147e-02, -1.1552e-02,  1.8523e-02, -4.3682e-03, -5.4253e-04,\n",
      "         1.3674e-02,  1.8758e-02,  2.2620e-02,  1.7732e-02,  1.0043e-02,\n",
      "        -1.8461e-02,  4.8599e-03, -1.4447e-02, -2.5387e-03, -2.5827e-02,\n",
      "        -1.8894e-03, -7.2011e-08,  2.2853e-02,  1.5842e-02,  8.3117e-03,\n",
      "        -8.9241e-04,  8.9597e-03, -1.1430e-02,  5.3125e-03, -1.5599e-02,\n",
      "        -2.2029e-02,  7.4832e-03, -2.2528e-02,  6.0115e-03,  2.4040e-02,\n",
      "        -2.2578e-02, -3.9394e-03, -9.7034e-03, -1.3344e-02,  4.2832e-03,\n",
      "         1.0969e-02, -2.3998e-04,  1.3101e-02, -4.8214e-03, -2.0836e-02,\n",
      "        -4.1005e-04,  1.0010e-02,  6.8369e-03,  4.6866e-03,  2.7285e-02,\n",
      "        -1.7676e-02,  2.1931e-02, -2.1111e-02, -1.1362e-02,  2.0493e-02,\n",
      "        -1.7025e-02,  3.0714e-03, -1.7416e-02, -1.8669e-02,  2.0501e-02,\n",
      "        -1.5873e-02,  2.2013e-04,  2.2350e-02,  5.5784e-05, -1.6032e-02,\n",
      "        -3.2775e-03,  1.1841e-02, -1.5694e-02, -1.3180e-02,  3.0711e-03,\n",
      "         6.0929e-03, -7.4694e-03, -1.4911e-02,  1.9471e-02, -2.2257e-02,\n",
      "         2.5355e-02,  6.8170e-03,  6.2632e-03, -1.0276e-02,  1.3555e-02,\n",
      "        -2.0238e-02,  1.3637e-02,  1.4437e-02, -8.2044e-03,  4.2020e-03,\n",
      "         2.4267e-03,  9.4191e-03, -4.8843e-03,  1.6896e-02, -8.9574e-03,\n",
      "         9.1387e-03, -1.5843e-02,  9.3999e-03, -1.8686e-02,  2.1805e-02,\n",
      "         1.9276e-02,  2.0678e-02, -9.8941e-03,  1.1233e-02,  8.2136e-03,\n",
      "        -1.1002e-02, -1.1544e-02,  1.5236e-02, -7.1598e-03, -6.7852e-03,\n",
      "        -4.3050e-03, -2.2354e-02, -2.2901e-02, -4.1387e-03,  3.0730e-03,\n",
      "        -1.7638e-02, -1.0220e-02,  2.3362e-02, -8.9590e-03,  5.1586e-03,\n",
      "        -1.2941e-02, -1.7532e-03,  5.3945e-03,  2.3745e-02, -1.4011e-02,\n",
      "        -3.1002e-03,  1.0873e-02, -1.7600e-02,  4.7609e-03, -1.9411e-02,\n",
      "         3.8414e-03, -4.0989e-03, -4.5715e-03, -8.4770e-03,  1.0656e-02,\n",
      "         1.0426e-03, -2.0452e-03, -3.8329e-03,  1.2222e-02,  6.9152e-03,\n",
      "        -1.5156e-02,  1.1893e-02,  3.6958e-03,  1.7184e-02,  1.4435e-02,\n",
      "        -3.6275e-03,  8.7670e-03,  3.8964e-03,  9.0825e-03, -1.9621e-02,\n",
      "        -1.0023e-02,  1.1358e-02, -1.2003e-02, -6.5284e-03,  3.8786e-03,\n",
      "         7.3279e-03, -1.5276e-02,  1.8399e-02, -1.8065e-02,  1.8457e-02,\n",
      "        -7.1719e-03, -3.8587e-03, -1.6067e-02, -2.5923e-02, -1.2190e-02,\n",
      "        -2.7030e-02,  3.8313e-03, -1.2696e-02, -1.9863e-02, -1.5682e-02,\n",
      "        -4.6848e-03, -3.6946e-03, -2.3954e-02, -2.2596e-02,  2.9807e-03,\n",
      "         1.3032e-03,  8.9972e-03,  1.1951e-02, -3.0297e-03, -1.7650e-02,\n",
      "        -1.6658e-02,  2.1158e-02,  1.5346e-02,  2.1130e-02, -2.1449e-02,\n",
      "         7.2000e-04, -9.3709e-03, -9.5949e-03, -1.4920e-02,  1.3084e-02,\n",
      "        -2.5741e-02, -5.8700e-03,  4.1869e-03, -1.8410e-02, -1.2480e-02,\n",
      "         4.8975e-03,  1.0587e-02,  1.0811e-02,  1.5866e-02, -3.6571e-03,\n",
      "        -8.9624e-03,  1.7696e-02], device='cuda:0')), ('FC.2.weight', tensor([[ 0.0520,  0.0357, -0.0317,  ...,  0.0334, -0.0785, -0.0080],\n",
      "        [ 0.0291,  0.0641,  0.0378,  ..., -0.0248, -0.0396,  0.1158],\n",
      "        [-0.0042,  0.0529, -0.1494,  ...,  0.0268,  0.0608,  0.0311],\n",
      "        ...,\n",
      "        [ 0.1129,  0.0069,  0.0066,  ..., -0.0707,  0.0283, -0.0657],\n",
      "        [ 0.0474,  0.0068,  0.0072,  ..., -0.0275,  0.0292, -0.0769],\n",
      "        [ 0.1133, -0.0137,  0.0560,  ...,  0.0649,  0.0080,  0.0084]],\n",
      "       device='cuda:0')), ('FC.2.bias', tensor([-3.8933e-02,  1.1405e-02, -4.5764e-03,  1.4394e-02, -1.0055e-02,\n",
      "        -2.8068e-02, -5.3631e-03, -1.4417e-02,  4.8280e-03,  3.2253e-02,\n",
      "         1.0319e-02,  3.9658e-03,  8.0504e-03,  1.8336e-02,  8.0779e-03,\n",
      "        -2.6133e-02,  2.1274e-02, -4.7796e-02,  2.4329e-02, -5.8292e-03,\n",
      "        -4.7594e-02, -1.2047e-02, -1.1308e-02, -3.7609e-02,  2.9634e-02,\n",
      "         9.7951e-03, -2.0354e-02,  2.6473e-02,  3.3928e-03, -9.1541e-03,\n",
      "         1.8956e-02,  1.7191e-02,  5.8224e-03, -1.3453e-02, -3.8516e-02,\n",
      "        -3.6674e-02, -4.1058e-02, -2.5351e-02, -1.8716e-02,  4.4628e-02,\n",
      "        -3.1717e-02,  7.4953e-04,  2.0123e-03, -9.1634e-03,  1.6880e-02,\n",
      "         1.0403e-03, -3.5651e-02, -9.9823e-03,  7.4162e-03, -9.9528e-03,\n",
      "         4.5600e-02, -2.6834e-02, -5.2002e-03,  2.6319e-02, -3.7785e-02,\n",
      "         1.7305e-02, -3.9500e-02, -2.9298e-02, -3.3315e-03,  3.5763e-02,\n",
      "         9.4207e-04,  3.8773e-03, -7.4805e-03,  3.3078e-02,  2.0586e-03,\n",
      "         3.0105e-02,  1.1829e-02, -2.0853e-02,  1.1284e-02, -2.0972e-03,\n",
      "         3.4957e-02, -5.3244e-03, -1.5490e-02, -1.6281e-02,  4.3711e-02,\n",
      "        -2.9551e-02,  1.6738e-02, -2.5116e-02, -2.8825e-02, -4.3550e-02,\n",
      "         1.3202e-03, -7.7133e-03, -3.8525e-03,  3.0713e-02,  2.2707e-02,\n",
      "        -4.5464e-02, -2.6036e-02, -4.2555e-03,  1.5283e-02,  1.3413e-02,\n",
      "        -1.4193e-02,  8.5801e-03,  2.7689e-02,  3.5195e-02, -1.1781e-02,\n",
      "         5.2974e-03,  2.0859e-03,  1.5529e-02, -4.5691e-02, -8.4263e-03,\n",
      "        -2.3902e-02,  4.8173e-03,  2.4581e-02,  2.9584e-02, -2.0292e-02,\n",
      "        -3.0650e-02, -2.4224e-02,  2.2943e-02, -6.5774e-03, -3.5317e-02,\n",
      "        -4.4118e-02,  2.9009e-02,  8.7862e-03,  1.3247e-03,  3.2306e-02,\n",
      "         5.0180e-03,  2.4601e-02, -2.6904e-02, -7.8808e-03, -3.5974e-02,\n",
      "         2.7511e-02,  2.6150e-02,  3.3718e-02, -7.0781e-03, -1.0869e-02,\n",
      "        -2.9109e-02, -1.6391e-02,  2.0844e-02, -1.7686e-02, -2.3367e-02,\n",
      "        -1.4601e-02,  2.1339e-02,  4.0499e-04,  2.6264e-02,  3.4581e-02,\n",
      "         2.0564e-02,  1.0930e-02,  2.7548e-02,  8.6942e-03, -9.2488e-06,\n",
      "        -1.1550e-02, -3.1744e-03,  3.6108e-02,  8.8776e-03, -3.2147e-02,\n",
      "         1.4493e-03, -5.4180e-02,  2.8368e-02, -5.9714e-03, -4.2247e-02,\n",
      "         1.4342e-02,  4.5199e-03,  2.6806e-02, -1.3666e-03, -2.2424e-02,\n",
      "        -9.0187e-03, -6.2032e-03, -2.3324e-02, -2.3789e-02,  2.9895e-02,\n",
      "        -6.5950e-03,  4.7353e-02,  1.1733e-03, -1.5439e-02,  2.3770e-02,\n",
      "         3.5087e-03, -3.6933e-03, -3.8911e-02, -2.6694e-02, -3.3985e-02,\n",
      "         1.6605e-03, -1.4423e-02,  1.2794e-02, -1.9910e-02, -2.8647e-02,\n",
      "         1.3758e-02, -8.7707e-03, -3.7465e-02,  1.6863e-02,  2.4301e-02,\n",
      "         1.1589e-02,  1.5384e-02, -1.4557e-02,  2.7401e-02,  1.5099e-03,\n",
      "        -4.1899e-02,  3.5894e-02, -3.4009e-02,  2.1687e-02,  4.4139e-03,\n",
      "        -1.0936e-02, -2.7939e-02,  8.1705e-03, -2.9348e-02, -2.3991e-02,\n",
      "         2.1386e-02,  2.5089e-02, -2.8949e-02, -4.9092e-03, -1.2869e-03,\n",
      "         1.1348e-03, -4.0788e-02,  4.0780e-02,  3.9316e-02, -1.7203e-02,\n",
      "         3.4951e-03, -3.6233e-02,  3.6759e-02,  1.1146e-02,  2.9072e-02,\n",
      "         2.1155e-02, -3.6789e-02, -3.0722e-02, -5.2294e-02,  5.8180e-03,\n",
      "         1.7221e-02,  3.2890e-02, -3.9135e-02, -2.0656e-02, -1.3357e-02,\n",
      "        -3.8114e-02,  4.4058e-02, -4.3168e-02, -4.7782e-02,  4.1886e-02,\n",
      "        -1.4349e-02, -4.0522e-03, -1.2630e-02, -1.0816e-02,  2.2207e-02,\n",
      "        -6.8971e-03,  1.9516e-02,  2.3740e-02, -2.8142e-02,  1.7490e-02,\n",
      "        -4.4424e-02, -3.5446e-02, -4.1242e-02,  2.9592e-02,  1.8311e-02,\n",
      "        -6.9588e-03, -6.1622e-03,  2.1889e-02, -5.4996e-03,  2.7783e-02,\n",
      "        -1.0718e-03, -1.7586e-02,  2.6025e-02, -2.2231e-03, -4.3526e-03,\n",
      "        -7.0693e-03,  1.7685e-02, -3.9116e-02,  2.8640e-02, -2.3018e-02,\n",
      "         4.2444e-02], device='cuda:0')), ('FC.3.weight', tensor([[-5.0171e-02,  1.0345e-01, -9.8654e-02, -2.5096e-02,  3.1641e-02,\n",
      "         -8.6406e-02,  8.2642e-02,  1.8130e-02,  2.9390e-02,  2.6725e-02,\n",
      "          1.1087e-02,  3.9203e-03,  4.5251e-02,  9.1734e-03, -1.0015e-01,\n",
      "         -1.1840e-04, -4.1148e-02,  8.4638e-02,  3.9222e-02, -4.5919e-02,\n",
      "         -5.7915e-02,  1.5190e-01,  5.3047e-02,  2.0314e-01, -8.3922e-03,\n",
      "         -7.6021e-02, -3.7337e-02,  1.8998e-01,  9.3865e-02, -5.5944e-02,\n",
      "         -5.3950e-02, -2.2714e-02, -7.7732e-02,  7.4943e-02, -4.1751e-02,\n",
      "         -4.2152e-03,  6.5179e-02,  1.0004e-01,  2.0298e-01,  2.2615e-03,\n",
      "          3.0527e-02,  1.7291e-01, -2.0682e-03, -2.8523e-03,  1.3267e-01,\n",
      "          4.7223e-02,  1.5723e-01, -1.0075e-01, -1.4226e-01,  1.2755e-01,\n",
      "          8.5348e-02, -1.8056e-02, -5.1546e-02, -4.8444e-02, -5.2555e-02,\n",
      "          7.3078e-02,  7.4262e-04,  1.7247e-02,  6.7868e-02,  9.3792e-02,\n",
      "         -1.4744e-01,  3.7212e-03, -7.6479e-03,  7.1476e-02, -5.1714e-02,\n",
      "         -4.2046e-02, -4.3355e-02,  3.6288e-02,  6.5435e-02,  1.0829e-01,\n",
      "          6.1412e-02,  6.1434e-02,  8.4699e-02, -2.4340e-02,  3.9991e-02,\n",
      "          6.2596e-02, -8.3694e-02,  7.8340e-02, -1.3642e-02, -3.2723e-02,\n",
      "          1.2729e-01,  2.4686e-02, -3.8239e-02, -6.8417e-02,  1.0647e-01,\n",
      "         -3.5781e-04,  2.1510e-02, -7.5539e-02,  8.5521e-03, -1.5021e-02,\n",
      "         -6.3165e-02,  1.3987e-01, -1.8447e-01, -6.8466e-02, -6.2607e-02,\n",
      "         -1.0835e-01, -3.8421e-02, -9.1629e-03, -7.7208e-02,  2.7857e-02,\n",
      "         -1.3321e-01,  2.2055e-02,  1.4065e-02,  7.2498e-02, -2.2567e-02,\n",
      "         -4.5520e-02, -9.9216e-02,  5.2440e-03,  9.9708e-02,  1.1809e-01,\n",
      "          6.4265e-02,  1.3052e-02,  2.5113e-02,  7.8072e-02,  1.1082e-01,\n",
      "         -2.3123e-01,  7.2367e-02,  7.2823e-02,  2.3798e-02,  5.7561e-02,\n",
      "          1.7865e-02, -1.5135e-02,  6.1653e-02, -1.1368e-01, -2.2429e-02,\n",
      "          7.7810e-02,  2.6073e-02,  2.0879e-02, -8.7004e-02, -2.7590e-02,\n",
      "         -5.8252e-02, -6.3311e-02, -3.7480e-02, -4.8261e-02, -1.0937e-02,\n",
      "          3.9132e-03,  9.6747e-02, -1.1269e-01,  5.4435e-02, -6.3968e-03,\n",
      "         -5.2718e-02,  4.2366e-02, -3.0126e-02, -1.9520e-01,  5.1164e-02,\n",
      "         -5.7414e-02, -8.9542e-02,  1.7963e-01,  1.4199e-01, -7.5824e-02,\n",
      "         -8.0778e-02, -2.3022e-01,  3.8046e-02,  1.8772e-02,  4.2768e-02,\n",
      "         -4.7186e-02, -1.1357e-02,  2.5500e-02,  3.3707e-02, -6.0429e-02,\n",
      "         -8.2128e-02,  7.1059e-02,  4.2738e-02, -1.1282e-01,  3.6478e-02,\n",
      "         -8.8341e-03,  4.3398e-02,  4.9492e-02, -1.9603e-02,  2.0841e-02,\n",
      "         -6.1693e-02, -8.5216e-03, -4.7593e-02,  3.6442e-02, -2.8179e-03,\n",
      "          6.5727e-02,  1.0267e-01,  3.2478e-02, -3.0827e-02,  5.1999e-02,\n",
      "         -4.6967e-02,  2.6453e-02, -1.6268e-02, -3.6450e-02,  9.1341e-02,\n",
      "         -2.3525e-04,  4.3795e-02, -9.4242e-03,  4.2023e-02,  8.3351e-02,\n",
      "          4.6488e-02, -2.4677e-02, -1.1140e-01,  2.0935e-01,  4.5508e-02,\n",
      "         -1.2810e-02, -3.7959e-02, -6.0952e-03,  6.0435e-02,  1.6663e-02,\n",
      "         -7.2204e-02, -8.9197e-03,  5.2832e-02, -2.5330e-02,  5.9709e-02,\n",
      "          1.3102e-01, -8.2932e-02, -1.3291e-01,  1.4787e-02, -7.5405e-02,\n",
      "          9.4182e-03, -9.3152e-02, -7.0041e-02, -2.6328e-03,  8.1957e-02,\n",
      "          5.0173e-02,  1.5071e-03, -2.5721e-02, -7.0290e-02,  6.6745e-03,\n",
      "          1.0792e-02,  6.7911e-02, -9.2800e-02, -3.1109e-02,  1.6852e-01,\n",
      "          1.0262e-03, -2.9979e-02, -4.7052e-02,  2.3118e-02,  9.2336e-02,\n",
      "          2.7206e-02,  9.5511e-02,  1.6669e-01, -3.7612e-02,  2.2835e-02,\n",
      "         -5.2503e-02, -7.9345e-02,  1.3082e-01,  1.0554e-01,  6.3648e-03,\n",
      "          9.0194e-02, -2.6101e-02,  8.0893e-02, -5.5694e-02,  4.5252e-04,\n",
      "          4.3217e-02, -7.8335e-02,  1.7051e-01,  2.0153e-01, -1.5311e-01,\n",
      "         -2.7937e-04,  5.1318e-02, -2.3799e-02, -8.1850e-02,  8.0765e-02,\n",
      "          8.2218e-02]], device='cuda:0')), ('FC.3.bias', tensor([0.0564], device='cuda:0'))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb> p state_dict.keys()\n",
      "odict_keys(['mu', 'dev', 'gconv1.0.A', 'gconv1.0.W.weight', 'gconv1.0.W.bias', 'gconv1.0.gate.weight', 'gconv1.0.gate.bias', 'gconv1.1.A', 'gconv1.1.W.weight', 'gconv1.1.W.bias', 'gconv1.1.gate.weight', 'gconv1.1.gate.bias', 'gconv1.2.A', 'gconv1.2.W.weight', 'gconv1.2.W.bias', 'gconv1.2.gate.weight', 'gconv1.2.gate.bias', 'FC.0.weight', 'FC.0.bias', 'FC.1.weight', 'FC.1.bias', 'FC.2.weight', 'FC.2.bias', 'FC.3.weight', 'FC.3.bias'])\n",
      "--KeyboardInterrupt--\n",
      "\n",
      "KeyboardInterrupt: Interrupted by user\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da1631b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
